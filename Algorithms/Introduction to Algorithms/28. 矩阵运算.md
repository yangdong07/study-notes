主要内容：
- 矩阵概念和性质
- 矩阵乘法的Strassen算法
- 求解线性方程组的LUP分解方法
- 矩阵求逆
- 对称正定矩阵及Schur补
- 最小二乘逼近

## 矩阵概念和性质
- **矩阵（matrix）**， $\boldsymbol{A} = (a_{ij})$
- $m \times n$ 矩阵： $m$ 行， $n$ 列
- 元素为实数的所有 $m \times n$ 矩阵用 $\mathbf{R}^{m\times n}$ 表示
- 元素属于集合 $S$ 的所有 $m \times n$ 矩阵的集合用 $ S^{m\times n}$ 表示
- 矩阵 $\boldsymbol{A}$ 的**转置（transpose）**记为 $\boldsymbol{A}^T$
- **向量（vector）**是数字的一维阵列，可以看成 $n \times 1$ 矩阵
- **单位向量 $\boldsymbol{e}_i$** 是第$i$ 个元素为 1，其他元素为0的向量。
- **零矩阵** 所有元素都是0的矩阵
- ** $n \times n$ 方阵**：
  - **对角矩阵**：所有非对角线上的元素均为0
  - **单位矩阵（identity matrix） $\boldsymbol{I}_n$ **：对角元素都是1的对角矩阵
  - **三对角矩阵（tridiagonal matrix） $\boldsymbol{T}$**：对角线和对角线附近两条线之外的元素均为0： 对 $|i - j| > 1$，元素 $t_{ij} = 0$
  - **上三角矩阵（upper-triangular matrix）$\boldsymbol{U}$**：对$ i > j$，有 $u_{ij} = 0$
  - **下三角矩阵（lower-triangular matrix）$\boldsymbol{L}$**：对$ i < j$，有 $l_{ij} = 0$
  - **置换矩阵（permutation matrix）$\boldsymbol{P}$**：每一行或列中都只有一个1，其他元素都为0。
  - **对称矩阵（symmetric matrix）$\boldsymbol{A}$** 满足：$\boldsymbol{A} = \boldsymbol{A}^T$

### 矩阵的运算
- 加法
- 乘法：矩阵必须是**相容**的
- 标量乘积 $ \lambda \boldsymbol{A} = (\lambda a_{ij}) $
- 乘法满足结合律，不满足交换律
- 向量与向量的乘积，设 $\boldsymbol{x} $ 和 $\boldsymbol{y}$ 都是 $n$ 维向量：
  - $\boldsymbol{x}^T \boldsymbol{y}$ 为$ \boldsymbol{x}$ 和 $\boldsymbol{y}$ 的**内积**，是一个实数
  - $\boldsymbol{x} \boldsymbol{y}^T$ 为$ \boldsymbol{x}$ 和 $\boldsymbol{y}$ 的**外积**，是一个 $n\times n $ 的矩阵，其中 $z_{ij} = x_i y_i$
- $n$ 维向量 $\boldsymbol{x}$ 的**（欧式）范数（euclidean norm）**定义为 ： $\|\boldsymbol{x}\| = (x_1^2 + x_2^2 + \cdots + x_n^2)^{1/2} = (\boldsymbol{x}^T\boldsymbol{x})^{1/2}$

### 矩阵的逆、秩和行列式
- 方阵的**逆矩阵（inverse）** 用 $\boldsymbol{A}^{-1}$表示，满足 $\boldsymbol{A} \boldsymbol{A}^{-1} = \boldsymbol{A}^{-1} \boldsymbol{A} = \boldsymbol{I}_n$
- 并非所有矩阵都有逆矩阵，有逆矩阵的矩阵称为**可逆**，或**非奇异矩阵**；没有逆矩阵的矩阵称为**不可逆矩阵**，或**奇异矩阵**
- 非零 $m \times n$矩阵 $\boldsymbol{A}$ 的**列秩（column rank）** 是指 $\boldsymbol{A}$ 的极大线性无关列向量组中向量的个数。 $\boldsymbol{A}$ 的**行秩（row rank）**是指$\boldsymbol{A}$ 的极大线性无关行向量组中向量的个数。任意矩阵的一个基本性质就是其行秩和列秩总是相等，也可以简单的称为 $\boldsymbol{A}$ 的**秩**。
- 如果一个 $n \times n$ 的方阵的秩为 $n$， 则它是 **满秩（full rank）**。 类似还有定义： **列满秩**和**行满秩**。
- **一个方阵满秩当且仅当它为非奇异矩阵**
- 矩阵 $\boldsymbol{A}$ 的**空向量（null vector）** 是指满足 $\boldsymbol{A} \boldsymbol{x} = 0 $ 的一个非零向量 $\boldsymbol{x}$。
- **当且仅当 $\boldsymbol{A}$ 无空向量时， $\boldsymbol{A}$ 为列满秩**
- **余子式（minor）**：对于 $n > 1$， $n \times n$ 矩阵 $\boldsymbol{A}$ 的第 $ij$ 个余子式是把 $\boldsymbol{A}$ 的第 $i$ 行和 第 $j$ 列的元素去掉后形成的一个$(n -1) \times (n-1)$ 矩阵 $\boldsymbol{A}_{[ij]}$
- **主子式**： 定义 $\boldsymbol{A}$ 的第 $k$ 个前导子矩阵 $\boldsymbol{A}_k$ 为$\boldsymbol{A}$ 的前 $k$ 行和前 $k$ 列交叉的元素组成的矩阵，也称为 $\boldsymbol{A}$ 的主子式。
- **行列式（determinant）**：可用余子式递归定义如下： $$ \text{det}(\boldsymbol{A}) = \left\{ \begin{array} {l} a_{11} \quad if \ n = 1 \\ \sum_{j=1}^n{(-1)^{1+j} a_{1j} \text{det}(\boldsymbol{A}_{[1, j]})}  \end{array} \right . $$ 特别地，对 $2 \times 2$ 矩阵有： $\text{det}(\boldsymbol{A}) = a_{11}a_{22} - a_{12}a_{21}$。 行列式具有以下性质：
  - 如果 $\boldsymbol{A}$ 的任何行或列的元素为 0，则 $\text{det}(\boldsymbol{A}) = 0$
  - 用常数 $\lambda$ 乘 $\boldsymbol{A}$ 的任意一行或列得到的矩阵的行列式，等于 $\lambda \text{det}(\boldsymbol{A})$
  - $\boldsymbol{A}$ 的行列式中一行（或一列）元素加上另一行（或另一列）中的相应元素，行列式的值不变
  - $\boldsymbol{A}$ 的行列式与 $\boldsymbol{A}^T$ 的行列式值相等
  - 行列式的任意两行（或两列）互换，其值异号

### 正定矩阵 postive-definite matrix
对于一个 $n \times n$ 的矩阵 $\boldsymbol{A}$ ，如果对所有 $n$ 维向量 $\boldsymbol{x} \neq 0$，有 $ \boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x} > 0$，则称 $\boldsymbol{A}$ 为** 正定矩阵**

**对任意列满秩矩阵 $\boldsymbol{A}$，矩阵 $\boldsymbol{A}^T\boldsymbol{A}$ 都是正定的。**

### 对称正定矩阵
**任意对称正定矩阵都是非奇异矩阵**

**如果 $\boldsymbol{A}$ 是一个对称正定矩阵，则 $\boldsymbol{A}$ 的每一个主子式都是对称正定的**

**Schur补**：如果$\boldsymbol{A}$ 是一个对称正定矩阵，将 $\boldsymbol{A}$ 划分成 ：
$$\begin{gather*}  \boldsymbol{A} =
\begin{pmatrix} \boldsymbol{A}_k & \boldsymbol{B}^T \\ \boldsymbol{B} & \boldsymbol{C} \end{pmatrix}
\end{gather*} $$  定义矩阵 $\boldsymbol{A}$ 关于 $\boldsymbol{A}_k$ 的Schur补为：$$ \boldsymbol{S} = \boldsymbol{C} - \boldsymbol{B} \boldsymbol{A}_k^{-1} \boldsymbol{B}^T $$ 可以证明，Schur补也是对称正定的。



## 矩阵乘法的Strassen算法
设$\boldsymbol{A}$、 $\boldsymbol{B}$ 、$ \boldsymbol{C} $ 都是 $n \times n$ 方阵，希望计算 $\boldsymbol{C} = \boldsymbol{A} \boldsymbol{B} $
普通的矩阵乘法需要 $\Theta(n^3)$ 时间。
Strassen算法使用分治法思想，假设 $n$ 为2的幂。将 $\boldsymbol{A}$、 $\boldsymbol{B}$ 、$ \boldsymbol{C} $ 均划分成 四个 $n/2 \times n/2$ 矩阵，等式$\boldsymbol{C} = \boldsymbol{A} \boldsymbol{B} $ 可改写为如下形式：
$$\begin{gather*}
\begin{pmatrix} r & s \\ t & u \end{pmatrix} =
\begin{pmatrix} a & b \\ c & d \end{pmatrix}
\begin{pmatrix} e & f \\ g & h \end{pmatrix}
\end{gather*} $$ 其中 $$
\boldsymbol{r} = \boldsymbol{a} \boldsymbol{e} + \boldsymbol{b}\boldsymbol{g} \\
\boldsymbol{s} = \boldsymbol{a} \boldsymbol{f} + \boldsymbol{b}\boldsymbol{h} \\
\boldsymbol{t} = \boldsymbol{c} \boldsymbol{e} + \boldsymbol{d}\boldsymbol{g} \\
\boldsymbol{u} = \boldsymbol{c} \boldsymbol{f} + \boldsymbol{d}\boldsymbol{h} \\
$$ 运行时间  $T(n)$ 有以下递归式： $T(n) = 8T(n/2) + \Theta(n^2)$，但是解为 $T(n) = \Theta(n^3)$

Strassen 发现了另外一种不同的递归方法，该方法只需要计算7次递归的 $n/2 \times n/2$ 矩阵乘法，有以下递归式：$T(n) = 7T(n/2) + \Theta(n^2) = \Theta(n^{\lg 7} = O(n^{2.81})$

Strassen方法分为以下四个步骤：
1. 将输入矩阵 $\boldsymbol{A}$、 $\boldsymbol{B}$ 划分成 $n/2 \times n/2$ 的子矩阵
2. 运用 $\Theta(n^2)$ 次标量加法与减法运算，计算出14个  $n/2 \times n/2$ 的矩阵 $\boldsymbol{A}_1, \boldsymbol{B}_1, \boldsymbol{A}_2, \boldsymbol{B}_2, \cdots, \boldsymbol{A}_7, \boldsymbol{B}_7 $
3. 递归计算出7个矩阵的乘积 $\boldsymbol{P}_i = \boldsymbol{A}_i \boldsymbol{B}_i$， $i = 1, 2, \cdots, 7$
4. 使用 $\Theta(n^2)$ 次标量加法与减法运算，对 $\boldsymbol{P}_i$ 矩阵的各种组合进行求和或求差，计算出$\boldsymbol{C}$ 的四个子矩阵 $\boldsymbol{r}, \boldsymbol{s}, \boldsymbol{t}, \boldsymbol{u}$。

其中$\boldsymbol{A}_1, \boldsymbol{B}_1, \boldsymbol{A}_2, \boldsymbol{B}_2, \cdots, \boldsymbol{A}_7, \boldsymbol{B}_7 $ 可以通过某种方式从 $\boldsymbol{A}$、 $\boldsymbol{B}$的八个子矩阵中构造出来，然后通过 $\boldsymbol{P}_i $ 构造出 $\boldsymbol{C}$ 的四个子矩阵

### Strassen算法的意义
从实用的角度来看，Strassen算法通常不是矩阵乘法所选择的方法，有以下四点原因：
1. Strassen算法的运行时间中，常数因子比较大
2. 当矩阵是稀疏的时候，为稀疏矩阵设计的方法更快
3. Strassen算法不想简单方法那样具有数值稳定性。（_数值稳定性大概是指对一些非常小的树能够得出正确结果_）
4. 在递归层次中生成的子矩阵需要消耗空间

在稠密矩阵上的快速矩阵乘法： 当矩阵规模超过一个“交叉点”时，采用Strassen算法；一旦子问题的大小缩小到交叉点以下时，则改用简单方法。
交叉点的准确数值与系统有关。对于一个给定的系统，通常以实验决定交叉点。

矩阵乘法的上界明显是 $\Omega(n^2)$。目前最理想的上界是 $O(n^{2.376})$

## 求解线性方程组

问题： 线性方程组可以写成 $\boldsymbol{A} \boldsymbol{x} = \boldsymbol{b}$ 的形式。 如果 $\boldsymbol{A}$ 是非奇异矩阵，则有逆矩阵 $\boldsymbol{A}^{-1}$，并且 $\boldsymbol{x} = \boldsymbol{A}^{-1} \boldsymbol{b}$ 是唯一解。

求解线性方程组的问题可以用求矩阵的逆和矩阵乘法解决。但在实际应用中，这种方法的确定是**数值不稳定**。通常用 **LUP分解** 来解决此问题。

### LUP分解的主要思想

LUP分解的思想就是找出三个 $n \times n$ 的矩阵 $\boldsymbol{L}$ 、$\boldsymbol{U}$ 和 $\boldsymbol{P}$，满足 $$ \boldsymbol{P} \boldsymbol{A} = \boldsymbol{L} \boldsymbol{U}$$ 其中
- $\boldsymbol{L}$ 是一个单位下三角矩阵
- $\boldsymbol{U}$ 是一个上三角矩阵
- $\boldsymbol{P}$ 是一个置换矩阵

称满足以上条件的  $\boldsymbol{L}$ 、$\boldsymbol{U}$ 和 $\boldsymbol{P}$ 是矩阵 $\boldsymbol{A}$ 的一个 LUP分解。 在得到 $\boldsymbol{A}$ 的LUP分解后，可以计算出 $\boldsymbol{A} \boldsymbol{x} = \boldsymbol{b}$ 的解。 原等式两边同时乘以 $\boldsymbol{P}$，得到一个等价方程组 $$\boldsymbol{P}\boldsymbol{A} \boldsymbol{x} = \boldsymbol{L} \boldsymbol{U}\boldsymbol{x}  = \boldsymbol{P}\boldsymbol{b}$$ 先用“正向替换”计算出下三角线性系统 $\boldsymbol{L} \boldsymbol{y}  = \boldsymbol{P}\boldsymbol{b}$ 的解；然后用“逆向替换”计算出上三角线性系统 $ \boldsymbol{U} \boldsymbol{x} = \boldsymbol{y}$ 的解。

### 置换矩阵的数组表示形式
可以用数组 $\pi[1..n]$ 表示置换矩阵 $\boldsymbol{P}$， $\pi[i]$ 说明 $\boldsymbol{P}_{i, \pi[i]} = 1$，并且对 $j \neq \pi[i]$，有 $\boldsymbol{P}_{ij} = 0$。
对于 $ \boldsymbol{P}\boldsymbol{b}$ ，第 $i$ 个元素为  $b_{\pi[i]}$，实际上是选择了第 $\pi[i]$ 个元素。

### 正向替换和逆向替换
对于下三角线性系统，可以用正向替换方式求解。很容易观察出，从下三角线性系统 的第一行方程式可以得到第一个元素的解，然后替换到第二个方程式可以得到第二个元素的解……

对于上三角线性系统，可以用逆向替换方法得到一个解。

如果给定了  $\boldsymbol{L}$ 、$\boldsymbol{U}$ 、 $\boldsymbol{P}$ 和$\boldsymbol{b}$。 LUP-SOLVE 算法可以在 $\Theta(n^2)$ 时间内得到解 $\boldsymbol{x}$

### LU分解
考虑 $\boldsymbol{A}$ 是一个非奇异矩阵，并且 $\boldsymbol{P} = \boldsymbol{I}_n$，找出因式分解 $\boldsymbol{A} = \boldsymbol{L} \boldsymbol{U}$。

执行 LU分解的过程称为 **高斯消元法**，其主要思想是依次在各个方程中消去某个变量：先从其他方程中减去第一个方程的倍数，以消去第一个变量；然后从第三个及以后的方程中减去第二个方程的倍数，以消去第一个和第二个变量；继续上述过程，直到系统变成一个上三角矩阵形式，这个矩阵就是 $\boldsymbol{U}$。 矩阵 $\boldsymbol{L}$ 是由消去变量所使用的倍数组成。

### LUP分解
在LU分解过程中，如果 $a_{11} = 0$ 或者对过程中的任意 $a_{kk} = 0$，消元方法都是行不通的。此时需要在余下的方程组中选择一个置换一个上来。这就是LUP分解中需要包含一个置换矩阵 $\boldsymbol{P}$ 的原因。为了避免把0作为除数。 利用置换来避免除数为0（或者一个很小的数）的过程称为**选主元**。

选主元的过程可以是动态的（尾递归）的，每次选择“余下的”方程组中第一个非零系数变量最大的，然后置换到当前首位，然后用这个方程式消余下的方程式的变量。
在选主元的过程中就可以得到 置换矩阵 $\boldsymbol{P}$


LUP分解： LUP-DECOMPOSITION算法的运行时间为 $\Theta(n^3)$。
所以使用LUP分解方法求解线性系统解的算法的时间复杂度为 $\Theta(n^3) + \Theta(n^2) = \Theta(n^3)$


## 矩阵求逆
**矩阵求逆运算等价于矩阵乘法运算**，二者具有相同的运行时间界。
（可以通过 从矩阵求逆得到矩阵乘法结果，和从矩阵乘法得到矩阵的逆，二者具有相同的时间界来证明这一点）

### 根据 LUP分解计算逆矩阵
求逆矩阵可以看做是求 $\boldsymbol{A} \boldsymbol{X} = \boldsymbol{I}_n$ 的解。这个方程又可以看做是 $n$ 个方程 $\boldsymbol{A} \boldsymbol{X}_i = \boldsymbol{e}_i$ 的集合，其中 $\boldsymbol{X}_i$ 是 $\boldsymbol{X}$ 的第$i$ 列。 如果已经得到了 $\boldsymbol{A} $ 的LUP分解，每个这样的方程可以在 $\Theta(n^2)$ 时间内计算出，所以总运行时间为 LUP分解时间 加上求解时间，为 $\Theta(n^3) + n \Theta(n^2)$ = $\Theta(n^3)$

## 最小二乘逼近

对给定的一组数据的点进行曲线拟合是对称正定矩阵的一个重要应用。假设给定 $m$ 个数据点 $(x_1, y_1), (x_2, y_2), \cdots, (x_m, y_m)$，其中已知 $y_i$ 收到测量误差的影响。我们希望找出一个函数 $F(x)$ ，使得近似误差 $ \eta_i = F(x_i) - y_i$ 很小。
函数 $F(x)$ 的形式依赖于我们所遇到的问题，假设具有线性形式：
$$ F(x) = \sum_{j=1}^n{c_jf_j(x)}$$  其中 $n$ 和基函数 $f_j(x)$ 取决于我们对问题的了解。 一种选择是 $f_j(x) = x^{j-1}$，这样就有：$$ F(x) = c_1 + c_2x + c_3x^2 + \cdots + c_nx^{n-1}$$

对于 $m$ 个点，如果选择 $n = m$，可以得到一个很精确的高次函数 $F$。但是没必要。这样的一个高次函数尽管容易处理数据，也容易对数据产生干扰。一般选择 比 $m$ 小得多的 $n$。

设
$$\begin{gather*}  \boldsymbol{A} =
\begin{pmatrix}  f_1(x_1) & f_2(x_1) & \cdots & f_n(x_1) \\
f_1(x_2) & f_2(x_2) & \cdots & f_n(x_2) \\
\vdots &\vdots &\ddots& \vdots \\
f_1(x_m) & f_2(x_m) & \cdots & f_n(x_m)  
\end{pmatrix}
\end{gather*} $$ 表示基函数在给定点的值的矩阵。即 $a_{ij} = f_j(x_i)$， 设 $\boldsymbol{c} = (c_k)$表示所求系数组成的$n$ 维向量，有：$$ \boldsymbol{\eta} = \boldsymbol{A} \boldsymbol{c} - \boldsymbol{y} $$ 是逼近误差的 $m$ 维向量。
为了使逼近误差最小，我们选定使 $\boldsymbol{\eta}$ 的范数最小，就得到一个**最小二乘解**，因为 $$ \| \boldsymbol{\eta} \| = {\left( \sum_{i=1}^m{\eta_i^2} \right)}^{1/2} $$ 又因为
$$ \| \boldsymbol{\eta} \|^2 = \| \boldsymbol{A} \boldsymbol{c} - \boldsymbol{y} \|^2 = \sum_{i=1}^m{\left( \sum_{j=1}^n{a_{ij}c_j - y_i}\right)^2}$$ 对每个 $c_k$ 求 $\| \boldsymbol{\eta} \|^2 $ 的微分并令结果为0，来求出 $\| \boldsymbol{\eta} \|$ 的最小值。
$$ \frac{\mathrm{d} \| \boldsymbol{\eta} \|^2}{\mathrm{d} c_k} = \sum_{i=1}^m{2{\left( \sum_{j=1}^n{a_{ij}c_j - y_i} \right) a_{ik}}} = 0$$  等价于下面的矩阵方程： $$ \left( \boldsymbol{A} \boldsymbol{c} - \boldsymbol{y} \right)^T \boldsymbol{A}  = 0$$ 或等价的 $$\boldsymbol{A}^T \left( \boldsymbol{A} \boldsymbol{c} - \boldsymbol{y} \right)  = 0$$ 这意味着 $$ \boldsymbol{A}^T \boldsymbol{A} \boldsymbol{c} = \boldsymbol{A}^T \boldsymbol{y}$$
在统计学中，该式称为 **正态方程（normal equation）**。 由于 $\boldsymbol{A}^T \boldsymbol{A}$ 是对称正定矩阵，所以方程的解为 $$  \boldsymbol{c} = \left(\boldsymbol{A}^T \boldsymbol{A} \right)^{-1} \boldsymbol{A}^T \boldsymbol{y} = \boldsymbol{A}^+$$
其中矩阵 $\boldsymbol{A}^+ =  \left(\boldsymbol{A}^T \boldsymbol{A} \right)^{-1} \boldsymbol{A}^T $称为矩阵 $\boldsymbol{A} $ 的 **伪逆矩阵**。 伪逆矩阵是逆矩阵概念在 $\boldsymbol{A}$ 不是方阵的情形中的自然推广。
